# Groq API Configuration
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-8b-instant

# HuggingFace API Configuration
HF_API_KEY=your_huggingface_token_here
# Image Classification Models (using actively maintained models from HF)
HF_IMAGE_CLASSIFICATION_MODEL=google/vit-base-patch16-224-in21k
# Alternative captioning models if this doesn't work:
# HF_IMAGE_CAPTIONING_MODEL=Salesforce/blip-image-captioning-base
# HF_IMAGE_CAPTIONING_MODEL=nlpconnect/vit-gpt2-image-captioning
HF_IMAGE_CAPTIONING_MODEL=Salesforce/blip-image-captioning-base

# Database Configuration (Use Neon DB for production, local Postgres for development)
# Production (Neon DB) - asyncpg uses 'ssl=require' not 'sslmode=require':
DATABASE_URL=postgresql+asyncpg://user:password@your-neon-db.neon.tech/dbname?ssl=require
# Local Development (Docker Compose):
# DATABASE_URL=postgresql+asyncpg://goml:goml_pass@localhost:5432/goml_db

# Redis Configuration (L2 Cache)
REDIS_URL=redis://localhost:6379/0
REDIS_TTL=3600

# Memcached Configuration (L1 Cache)
MEMCACHE_HOST=localhost
MEMCACHE_PORT=11211
MEMCACHE_TTL=300

# Application Settings
APP_NAME=AI Response Caching POC
DEBUG=true
